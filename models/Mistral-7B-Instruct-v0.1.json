{
  "_descriptorVersion": "0.0.1",  
  "datePublished": "2023-09-27T16:12:57",
  "name": "Mistral 7B Instruct v0.1",
  "description": "The Mistral-7B-Instruct-v0.1 is a Large Language Model (LLM) developed by Mistral AI. This LLM is an instruct fine-tuned version of a generative text model, leveraging a variety of publicly available conversation datasets. The model's architecture is based on a transformer model, featuring Grouped-Query Attention, Sliding-Window Attention, and a Byte-fallback BPE tokenizer. To utilize the instruction fine-tuning capabilities, prompts should be enclosed within [INST] and [/INST] tokens. The initial instruction should commence with a beginning-of-sentence id, whereas subsequent instructions should not. The generation process by the assistant will terminate with the end-of-sentence token id. For detailed information about this model, refer to the release blog posts by Mistral AI.",
  "author": {
    "name": "Mistral AI",
    "url": "https://mistral.ai/",
    "blurb": "Mistral AI's mission is to spearhead the revolution of open models."
  },
  "numParameters": "7B",
  "resources": {
    "canonicalUrl": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1",
    "paperUrl": "https://mistral.ai/news/announcing-mistral-7b/",
    "downloadUrl": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
  },
  "trainedFor": "chat",
  "arch": "mistral",
  "files": {
    "highlighted": {
      "economical": {
        "name": "mistral-7b-instruct-v0.1.Q4_K_S.gguf"
      },
      "most_capable": {
        "name": "mistral-7b-instruct-v0.1.Q6_K.gguf"
      }
    },
    "all": [
      {
        "name": "mistral-7b-instruct-v0.1.Q4_K_S.gguf",
        "url": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_S.gguf",
        "sizeBytes": 4140373664,
        "quantization": "Q4_K_S",
        "format": "gguf",
        "sha256checksum": "f1b7f1885029080be49aff49c83f87333449ef727089546e0d887e2f17f0d02e",
        "publisher": {
          "name": "TheBloke",
          "socialUrl": "https://twitter.com/TheBlokeAI"
        },
        "respository": "TheBloke/Mistral-7B-Instruct-v0.1-GGUF",
        "repositoryUrl": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
      },
      {
        "name": "mistral-7b-instruct-v0.1.Q6_K.gguf",
        "url": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q6_K.gguf",
        "sizeBytes": 5942064800,
        "quantization": "Q6_K",
        "format": "gguf",
        "sha256checksum": "dfb053cb8d5f56abde8f56899ffe0d23e1285a423df0b65ea3f3adbb263b22c2",
        "publisher": {
          "name": "TheBloke",
          "socialUrl": "https://twitter.com/TheBlokeAI"
        },
        "respository": "TheBloke/Mistral-7B-Instruct-v0.1-GGUF",
        "repositoryUrl": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
      },
      {
        "name": "ggml-model-q4_0.gguf",
        "url": "https://huggingface.co/baghelz/OpenHermes-2.5-neural-chat-v3-3-Slerp/resolve/main/ggml-model-q4_0.gguf",
        "sizeBytes": 4108916352,
        "quantization": "q4_0",
        "format": "gguf",
        "sha256checksum": "0d82f9d0e9d1757c81ffe6cc5f7cf47a772e87d0e7e24c8e742417e7e97646af",
        "publisher": {
          "name": "baghelz",
          "socialUrl": "https://twitter.com/ManishBaghelz"
        },
        "respository": "baghelz/OpenHermes-2.5-neural-chat-v3-3-Slerp",
        "repositoryUrl": "https://huggingface.co/baghelz/OpenHermes-2.5-neural-chat-v3-3-Slerp"
      },
      {
        "name": "ggml-model-q8_0-v2.gguf",
        "url": "https://huggingface.co/baghelz/OpenHermes-2.5-neural-chat-v3-3-Slerp/resolve/main/ggml-model-q8_0-v2.gguf",
        "sizeBytes": 7695857280,
        "quantization": "q8_0",
        "format": "gguf",
        "sha256checksum": "aeff45c3bb4cbac4dd2adf19e1564235152e952725d9f15f527b333b40944d2e",
        "publisher": {
          "name": "baghelz",
          "socialUrl": "https://twitter.com/ManishBaghelz"
        },
        "respository": "baghelz/OpenHermes-2.5-neural-chat-v3-3-Slerp",
        "repositoryUrl": "https://huggingface.co/baghelz/OpenHermes-2.5-neural-chat-v3-3-Slerp"
     }
    ]
  }
}
